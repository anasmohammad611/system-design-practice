{
  "type": "excalidraw",
  "version": 2,
  "source": "https://excalidraw.com",
  "elements": [
    {
      "id": "oLLtOzz-7fXeZqAjZ05SJ",
      "type": "text",
      "x": -54.857259816236365,
      "y": 391.7587237319914,
      "width": 1199,
      "height": 7575,
      "angle": 0,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "a0",
      "roundness": null,
      "seed": 1584797196,
      "version": 102,
      "versionNonce": 1568290543,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1749882814898,
      "link": null,
      "locked": false,
      "text": "Distributed ID Generators - System Design Notes\n===============================================\n\nPurpose:\n--------\nGenerate globally unique IDs in a distributed system.\nMust be:\n- Unique\n- Fast\n- Scalable (multi-node)\n- (Optional) Sortable or roughly ordered\n\nUse Cases:\n----------\n- Database primary keys\n- Event logs\n- Messages / posts / comments\n- External references (URLs, public IDs)\n\nCore Properties:\n----------------\n1. Uniqueness (no collision)\n2. High throughput (1M+ IDs/sec)\n3. Decentralized (no single point)\n4. Order-preserving (if needed)\n\nID Generation Techniques:\n=========================\n\n1. UUID (Universally Unique ID)\n-------------------------------\nFormat: 128-bit random or time-based string\n\nPros:\n- No coordination required\n- Built-in in many languages\n\nCons:\n- Not ordered\n- Large (not index-friendly)\n- Hard to trace/debug\n\nExample (Python):\n-----------------\nimport uuid\nprint(str(uuid.uuid4()))\n\n2. Twitter Snowflake (64-bit ID)\n--------------------------------\nBit structure (left to right):\n[41 bits timestamp][10 bits node ID][12 bits sequence]\n\n- 41 bits = milliseconds since epoch (~69 years)\n- 10 bits = machine/datacenter ID\n- 12 bits = sequence number (0–4095 per ms)\n\nPros:\n- Sortable by time\n- Scales horizontally\n\nCons:\n- Needs synchronized clocks\n- Clock rollback breaks system\n- Sequence reset logic can fail under burst traffic\n- Cannot guarantee *global* monotonicity across all API servers\n\nSimplified Python Implementation:\n---------------------------------\nEPOCH = 1650000000000\nnode_id = 7\nsequence = 0\nlast_ts = -1\n\ndef current_millis():\n    return int(time.time() * 1000)\n\ndef generate_id():\n    global sequence, last_ts\n    now = current_millis()\n    if now == last_ts:\n        sequence = (sequence + 1) & 0xFFF\n        if sequence == 0:\n            while now <= last_ts:\n                now = current_millis()\n    else:\n        sequence = 0\n    last_ts = now\n    return ((now - EPOCH) << 22) | (node_id << 12) | sequence\n\n3. Instagram's ID System (Sharded Database IDs)\n-----------------------------------------------\nGoal: Let multiple API servers write safely without coordination.\n\nTechnique:\n- Instead of generating ID on API servers, IDs are generated at the **DB level**\n- Instagram uses **sharded MySQL** — each shard has an auto-increment primary key\n- To avoid collisions:\n  - Each shard uses **a different offset** and **increment step**\n\n  For example:\n    - Shard 0: starts at 1, step 10 → IDs: 1, 11, 21, ...\n    - Shard 1: starts at 2, step 10 → IDs: 2, 12, 22, ...\n    - Shard 2: starts at 3, step 10 → IDs: 3, 13, 23, ...\n    - ...\n\nResult:\n- Each DB generates IDs independently\n- The IDs are **interleaved**, but always unique\n\nWhy it works better for Instagram:\n----------------------------------\n- Avoids complex coordination logic in app tier\n- No time/clock dependency\n- Even if one DB fails, others continue generating\n- API servers don’t touch ID generation logic\n\nKey Tradeoffs:\n--------------\n- IDs are not ordered by creation time globally\n- Requires strict control of shard config (offset, step)\n- Slightly wastes ID space\n\nAdvantages Over Twitter’s Snowflake:\n------------------------------------\n- No clock dependency → safe from time sync failures\n- No need to run Snowflake service cluster\n- Better DB locality → app writes directly to correct shard\n- Stateless API servers → horizontally scalable without ID contention\n\nImplementation Sketch:\n----------------------\nMySQL config per shard:\n- Shard 0:\n  auto_increment = 1\n  auto_increment_increment = 10\n\n- Shard 1:\n  auto_increment = 2\n  auto_increment_increment = 10\n\n...\n\nInsert:\n  INSERT INTO posts (user_id, content) VALUES (...)\n\n  → ID is generated automatically by the DB.\n\n4. Redis-based INCR\n-------------------\nCentral Redis key used:\n  redis.incr(\"global_id\")\n\nPros:\n- Simple, fast\n- No duplicate IDs\n\nCons:\n- Centralized (Redis crash = data loss or pause)\n- Poor horizontal scalability\n\nPython Example:\n---------------\nimport redis\nr = redis.StrictRedis()\nid = r.incr(\"global_id\")\n\n5. Custom Hybrid ID (Time + Node ID + Random)\n---------------------------------------------\nFormat: (timestamp << N) | (node_id << M) | random_bits\n\nUseful when you don’t need full Snowflake complexity.\n\nPython Example:\n---------------\ndef generate_custom_id(node_id):\n    ts = int(time.time() * 1000)\n    rand_bits = random.getrandbits(12)\n    return (ts << 16) | (node_id << 12) | rand_bits\n\nDesign Considerations:\n----------------------\n- Global monotonicity vs eventual uniqueness\n- Clock rollback handling (Snowflake-sensitive)\n- Centralized bottlenecks (Redis/DB-based)\n- Shard-local ID generation (Instagram) works best at scale\n\nSummary:\n--------\n- Use UUID for non-sequential unique values (simple but unordered)\n- Use Snowflake when ordering is needed and you control infra\n- Use DB-sharded auto-increments for write-heavy, API-first architectures (Instagram)\n- Redis/DB sequences are easy but limited in scale\n- Always consider clock safety, retries, and load balancing\n\n\n-------------------------------------------------------------\n\nSystem Design — Distributed ID Generator\n\n---\n\nQuestion 1: Design a system to generate globally unique & monotonically increasing \nIDs across multiple data centers.\n\nThought Process:\n- Need high availability, global uniqueness, and global order.\n- Data centers have their own clocks → potential clock skew.\n- Can’t have a single point of failure (e.g., central DB).\n- Snowflake comes to mind, but does it solve all of this?\n\nInitial Approach:\n- Use Snowflake algorithm:\n  - 41 bits → timestamp (in ms)\n  - 10 bits → machine ID (assigned via Zookeeper or service)\n  - 12 bits → sequence number per ms\n- Each machine generates IDs locally.\n- Machine ID assigned centrally to avoid duplicates.\n\nWhy It’s Not Enough:\n- Snowflake does NOT guarantee **global** monotonicity.\n  - Clock drift between DCs → out-of-order IDs.\n- Machine ID duplication possible during crash/reboot.\n- If clock goes backward, ID collisions possible.\n\nIdeal Solution:\n- Use hybrid logical clock (HLC) or Google’s TrueTime (bound uncertainty).\n- Use a Raft-based sequencer in each region (optional fallback).\n- Optionally, accept \"eventual ordering\" with k-sortable IDs and fix during read.\n- For strict guarantees → use globally synchronized service like Spanner or add ordering layer in write path.\n\n---\n\nQuestion 2: Redis INCR used for ID generation; node crashes → duplicate IDs. \nWhat went wrong and how to fix?\n\nThought Process:\n- Redis `INCR` is atomic, but what about persistence?\n- If Redis crashes mid-operation, what happens to the latest increment?\n- Why would duplicate IDs come back after restart?\n\nRoot Cause:\n- Redis may lose latest increments if:\n  - Not using AOF (Append-Only File)\n  - Or AOF flush is delayed (`appendfsync everysec`)\n- Redis by default uses in-memory counters.\n- Crash = counter reset → previously generated IDs may be reused.\n\nAttempted Fix (Wrong):\n- Use 5 Redis nodes, do quorum read/write (3/5).\n- Problem: Redis is not multi-writer safe, no built-in quorum.\n- This adds complexity and is not Redis’s strength.\n\nIdeal Solution:\n1. Enable AOF + `appendfsync always` (write-slow, but safe).\n2. Or switch to etcd/Zookeeper which provide consensus and durability.\n3. Or move to Snowflake-style ID generator (stateless, in-memory, distributed).\n4. Ensure that Redis writes are persisted before acknowledging client.\n\nConcepts:\n- AOF: Append Only File, ensures Redis writes are saved to disk.\n- Quorum: Majority agreement (e.g. 3 of 5 nodes) to ensure consistency.\n- etcd/Zookeeper: Distributed coordination services with strong consistency.\n\n---\n\nQuestion 3: At 5M IDs/sec scale — users see out-of-order feeds, ID conflicts, \nand latency spikes.\n\nThought Process:\n- Out-of-order: Clock drift? Multiple sources generating IDs?\n- Conflicts: Possibly same machine ID on different nodes?\n- Latency spikes: Central service bottleneck? Disk writes?\n\nWhat Could Be Failing:\n- Snowflake timestamp skew due to clock drift.\n- Duplicate machine IDs on newly spawned nodes.\n- Centralized ID generator bottleneck (e.g., Redis with AOF).\n- Network/IO pauses or GC causing 500ms delay.\n- Redis crashed, restarted, lost last counter state → duplicate ID.\n\nIdeal Redesign:\n1. Use decentralized Snowflake-like generator per API server.\n   - Assign unique machine ID per node.\n   - Handle clock rollback → block or buffer requests.\n2. Validate machine ID uniqueness via Zookeeper or baked infra config.\n3. Optional fallback:\n   - Pre-allocate ID blocks from central allocator\n   - Or use Raft-based sequencer (for strict monotonicity)\n4. Ensure P99 < 5ms by making all ID generation local & in-memory.\n\nTrade-offs:\n- Snowflake = fast, scalable, but not perfect for global order.\n- Centralized counter = strict order, but lower throughput & single point of failure.\n- ID block allocation = better scale, but requires coordination.\n\nConcepts:\n- Snowflake: Bit-encoded ID generator using timestamp + nodeID + sequence.\n- HLC (Hybrid Logical Clock): Combines logical + physical time to handle skew.\n- TrueTime: Google’s bounded time uncertainty API used in Spanner.\n\n---\n\n",
      "fontSize": 20,
      "fontFamily": 8,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "Distributed ID Generators - System Design Notes\n===============================================\n\nPurpose:\n--------\nGenerate globally unique IDs in a distributed system.\nMust be:\n- Unique\n- Fast\n- Scalable (multi-node)\n- (Optional) Sortable or roughly ordered\n\nUse Cases:\n----------\n- Database primary keys\n- Event logs\n- Messages / posts / comments\n- External references (URLs, public IDs)\n\nCore Properties:\n----------------\n1. Uniqueness (no collision)\n2. High throughput (1M+ IDs/sec)\n3. Decentralized (no single point)\n4. Order-preserving (if needed)\n\nID Generation Techniques:\n=========================\n\n1. UUID (Universally Unique ID)\n-------------------------------\nFormat: 128-bit random or time-based string\n\nPros:\n- No coordination required\n- Built-in in many languages\n\nCons:\n- Not ordered\n- Large (not index-friendly)\n- Hard to trace/debug\n\nExample (Python):\n-----------------\nimport uuid\nprint(str(uuid.uuid4()))\n\n2. Twitter Snowflake (64-bit ID)\n--------------------------------\nBit structure (left to right):\n[41 bits timestamp][10 bits node ID][12 bits sequence]\n\n- 41 bits = milliseconds since epoch (~69 years)\n- 10 bits = machine/datacenter ID\n- 12 bits = sequence number (0–4095 per ms)\n\nPros:\n- Sortable by time\n- Scales horizontally\n\nCons:\n- Needs synchronized clocks\n- Clock rollback breaks system\n- Sequence reset logic can fail under burst traffic\n- Cannot guarantee *global* monotonicity across all API servers\n\nSimplified Python Implementation:\n---------------------------------\nEPOCH = 1650000000000\nnode_id = 7\nsequence = 0\nlast_ts = -1\n\ndef current_millis():\n    return int(time.time() * 1000)\n\ndef generate_id():\n    global sequence, last_ts\n    now = current_millis()\n    if now == last_ts:\n        sequence = (sequence + 1) & 0xFFF\n        if sequence == 0:\n            while now <= last_ts:\n                now = current_millis()\n    else:\n        sequence = 0\n    last_ts = now\n    return ((now - EPOCH) << 22) | (node_id << 12) | sequence\n\n3. Instagram's ID System (Sharded Database IDs)\n-----------------------------------------------\nGoal: Let multiple API servers write safely without coordination.\n\nTechnique:\n- Instead of generating ID on API servers, IDs are generated at the **DB level**\n- Instagram uses **sharded MySQL** — each shard has an auto-increment primary key\n- To avoid collisions:\n  - Each shard uses **a different offset** and **increment step**\n\n  For example:\n    - Shard 0: starts at 1, step 10 → IDs: 1, 11, 21, ...\n    - Shard 1: starts at 2, step 10 → IDs: 2, 12, 22, ...\n    - Shard 2: starts at 3, step 10 → IDs: 3, 13, 23, ...\n    - ...\n\nResult:\n- Each DB generates IDs independently\n- The IDs are **interleaved**, but always unique\n\nWhy it works better for Instagram:\n----------------------------------\n- Avoids complex coordination logic in app tier\n- No time/clock dependency\n- Even if one DB fails, others continue generating\n- API servers don’t touch ID generation logic\n\nKey Tradeoffs:\n--------------\n- IDs are not ordered by creation time globally\n- Requires strict control of shard config (offset, step)\n- Slightly wastes ID space\n\nAdvantages Over Twitter’s Snowflake:\n------------------------------------\n- No clock dependency → safe from time sync failures\n- No need to run Snowflake service cluster\n- Better DB locality → app writes directly to correct shard\n- Stateless API servers → horizontally scalable without ID contention\n\nImplementation Sketch:\n----------------------\nMySQL config per shard:\n- Shard 0:\n  auto_increment = 1\n  auto_increment_increment = 10\n\n- Shard 1:\n  auto_increment = 2\n  auto_increment_increment = 10\n\n...\n\nInsert:\n  INSERT INTO posts (user_id, content) VALUES (...)\n\n  → ID is generated automatically by the DB.\n\n4. Redis-based INCR\n-------------------\nCentral Redis key used:\n  redis.incr(\"global_id\")\n\nPros:\n- Simple, fast\n- No duplicate IDs\n\nCons:\n- Centralized (Redis crash = data loss or pause)\n- Poor horizontal scalability\n\nPython Example:\n---------------\nimport redis\nr = redis.StrictRedis()\nid = r.incr(\"global_id\")\n\n5. Custom Hybrid ID (Time + Node ID + Random)\n---------------------------------------------\nFormat: (timestamp << N) | (node_id << M) | random_bits\n\nUseful when you don’t need full Snowflake complexity.\n\nPython Example:\n---------------\ndef generate_custom_id(node_id):\n    ts = int(time.time() * 1000)\n    rand_bits = random.getrandbits(12)\n    return (ts << 16) | (node_id << 12) | rand_bits\n\nDesign Considerations:\n----------------------\n- Global monotonicity vs eventual uniqueness\n- Clock rollback handling (Snowflake-sensitive)\n- Centralized bottlenecks (Redis/DB-based)\n- Shard-local ID generation (Instagram) works best at scale\n\nSummary:\n--------\n- Use UUID for non-sequential unique values (simple but unordered)\n- Use Snowflake when ordering is needed and you control infra\n- Use DB-sharded auto-increments for write-heavy, API-first architectures (Instagram)\n- Redis/DB sequences are easy but limited in scale\n- Always consider clock safety, retries, and load balancing\n\n\n-------------------------------------------------------------\n\nSystem Design — Distributed ID Generator\n\n---\n\nQuestion 1: Design a system to generate globally unique & monotonically increasing \nIDs across multiple data centers.\n\nThought Process:\n- Need high availability, global uniqueness, and global order.\n- Data centers have their own clocks → potential clock skew.\n- Can’t have a single point of failure (e.g., central DB).\n- Snowflake comes to mind, but does it solve all of this?\n\nInitial Approach:\n- Use Snowflake algorithm:\n  - 41 bits → timestamp (in ms)\n  - 10 bits → machine ID (assigned via Zookeeper or service)\n  - 12 bits → sequence number per ms\n- Each machine generates IDs locally.\n- Machine ID assigned centrally to avoid duplicates.\n\nWhy It’s Not Enough:\n- Snowflake does NOT guarantee **global** monotonicity.\n  - Clock drift between DCs → out-of-order IDs.\n- Machine ID duplication possible during crash/reboot.\n- If clock goes backward, ID collisions possible.\n\nIdeal Solution:\n- Use hybrid logical clock (HLC) or Google’s TrueTime (bound uncertainty).\n- Use a Raft-based sequencer in each region (optional fallback).\n- Optionally, accept \"eventual ordering\" with k-sortable IDs and fix during read.\n- For strict guarantees → use globally synchronized service like Spanner or add ordering layer in write path.\n\n---\n\nQuestion 2: Redis INCR used for ID generation; node crashes → duplicate IDs. \nWhat went wrong and how to fix?\n\nThought Process:\n- Redis `INCR` is atomic, but what about persistence?\n- If Redis crashes mid-operation, what happens to the latest increment?\n- Why would duplicate IDs come back after restart?\n\nRoot Cause:\n- Redis may lose latest increments if:\n  - Not using AOF (Append-Only File)\n  - Or AOF flush is delayed (`appendfsync everysec`)\n- Redis by default uses in-memory counters.\n- Crash = counter reset → previously generated IDs may be reused.\n\nAttempted Fix (Wrong):\n- Use 5 Redis nodes, do quorum read/write (3/5).\n- Problem: Redis is not multi-writer safe, no built-in quorum.\n- This adds complexity and is not Redis’s strength.\n\nIdeal Solution:\n1. Enable AOF + `appendfsync always` (write-slow, but safe).\n2. Or switch to etcd/Zookeeper which provide consensus and durability.\n3. Or move to Snowflake-style ID generator (stateless, in-memory, distributed).\n4. Ensure that Redis writes are persisted before acknowledging client.\n\nConcepts:\n- AOF: Append Only File, ensures Redis writes are saved to disk.\n- Quorum: Majority agreement (e.g. 3 of 5 nodes) to ensure consistency.\n- etcd/Zookeeper: Distributed coordination services with strong consistency.\n\n---\n\nQuestion 3: At 5M IDs/sec scale — users see out-of-order feeds, ID conflicts, \nand latency spikes.\n\nThought Process:\n- Out-of-order: Clock drift? Multiple sources generating IDs?\n- Conflicts: Possibly same machine ID on different nodes?\n- Latency spikes: Central service bottleneck? Disk writes?\n\nWhat Could Be Failing:\n- Snowflake timestamp skew due to clock drift.\n- Duplicate machine IDs on newly spawned nodes.\n- Centralized ID generator bottleneck (e.g., Redis with AOF).\n- Network/IO pauses or GC causing 500ms delay.\n- Redis crashed, restarted, lost last counter state → duplicate ID.\n\nIdeal Redesign:\n1. Use decentralized Snowflake-like generator per API server.\n   - Assign unique machine ID per node.\n   - Handle clock rollback → block or buffer requests.\n2. Validate machine ID uniqueness via Zookeeper or baked infra config.\n3. Optional fallback:\n   - Pre-allocate ID blocks from central allocator\n   - Or use Raft-based sequencer (for strict monotonicity)\n4. Ensure P99 < 5ms by making all ID generation local & in-memory.\n\nTrade-offs:\n- Snowflake = fast, scalable, but not perfect for global order.\n- Centralized counter = strict order, but lower throughput & single point of failure.\n- ID block allocation = better scale, but requires coordination.\n\nConcepts:\n- Snowflake: Bit-encoded ID generator using timestamp + nodeID + sequence.\n- HLC (Hybrid Logical Clock): Combines logical + physical time to handle skew.\n- TrueTime: Google’s bounded time uncertainty API used in Spanner.\n\n---\n\n",
      "autoResize": true,
      "lineHeight": 1.25
    }
  ],
  "appState": {
    "gridSize": 20,
    "gridStep": 5,
    "gridModeEnabled": false,
    "viewBackgroundColor": "#000000",
    "lockedMultiSelections": {}
  },
  "files": {}
}